#' @title calculate_AUC_base
#' @description the base function of calculate_AUCs: build the model and calculate the AUCs
#'
#' @param n01_all size of all data labeled as class 0/1. For example, n01_all=c(800,800) represents that the size of all data labeled as class 0 is 800 and the size of all data labeled as class 1 is also 800.
#' @param n01_p size of pilot data labeled as class 0/1. For example, n01_p=c(15,15) represents that the size of pilot data labeled as class 0 is 15 and the size of pilot data labeled as class 1 is also 15.
#' @param n_train_sets size sets of training data labeled as class 0/1. For example, n_train_sets=c(c(30,30),c(90,90),c(150,150)) represents that we try 3 different sets of training data and the training size of the first set is c(30,30).
#' @param n01_test number of test data labeled as class 0/1. size of all data labeled as class 0/1. For example, n01_test=c(300,300) represents that the size of test data labeled as class 0 is 300 and the size of test data labeled as class 1 is also 300.
#' @param seed the seed you want to use to run simulations.
#' @param method
#' Choose the method you want to use: "pca2_mvnorm" , "gaussian_copula" or "smote"(\code{\link[smotefamily]{SMOTE}}).
#' The default value is "pca2_mvnorm".
#' @param model base classification model.
#' \itemize{
#' \item logistic: Logistic regression. \link{glm} function with family = 'binomial'
#' \item penlog: Penalized logistic regression with LASSO penalty. \code{\link[glmnet]{glmnet}} in \code{glmnet} package
#' \item svm: Support Vector Machines. \code{\link[e1071]{svm}} in \code{e1071} package
#' \item randomforest: Random Forest. \code{\link[randomForest]{randomForest}} in \code{randomForest} package
#' \item lda: Linear Discriminant Analysis. \code{\link[MASS]{lda}} in \code{MASS} package
#' \item slda: Sparse Linear Discriminant Analysis with LASSO penalty.
#' \item nb: Naive Bayes. \code{\link[e1071]{naiveBayes}} in \code{e1071} package
#' \item nnb: Nonparametric Naive Bayes. \code{\link[naivebayes]{naive_bayes}} in \code{naivebayes} package
#' \item ada: Ada-Boost. \code{\link[ada]{ada}} in \code{ada} package
#' \item xgboost: XGBboost. \code{\link[xgboost]{xgboost}} in \code{xgboost} package
#' \item tree: Classificatin Tree. \code{\link[tree]{tree}} in \code{tree} package
#' \item self: You can use your self-defined function. You need to pass your self-defined function via the "func" parameter.
#' }
#'
#' @param func If you set "model" to "self", you have to pass your self-defined model function. This function should be able to take "x_train" and "y_train" as the first two inputs to train the model and then take "x_test" as the third input and return the predicted scores of x_test data. For example, \cr\cr
#' \code{library(e1071)\cr\cr
#' predict_model <- function(x_train, y_train, x_test){ \cr
#' data_trainxy<-data.frame(x_train,y_train=as.factor(y_train)) \cr
#' fit_svm<-svm(y_train~.,data=data_trainxy,probability=TRUE) \cr
#' pred_svm <- predict(fit_svm, x_test, probability=TRUE,decision.values = TRUE) \cr
#' p_svm=as.data.frame(attr(pred_svm, "probabilities"))$"1" \cr
#' return(p_svm) \cr
#' }\cr \cr
#' AUC = calculate_AUC_base(n01_all= c(800,800), n01_p=c(15,15), n01_test=c(300,300), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), seed=1, model=c("self","randomforest"),func=predict_model)}
#'
#' @param data_generation a parameter list that you can tell the function about the distribution and parameters you want to use to generate the data.
#' \itemize{
#' \item "gaussian" represent multivariate gaussian distribution. see \code{\link[MASS]{mvrnorm}} in \code{MASS} package. For example, data_generation=list(dist="gaussian",sigma=list(class_0=diag(5),class_1=diag(5)),mu=c(rep(0,5),rep(2,5)))
#' \item "t-distribution" represent multivariate t distribution. see \code{\link[mvtnorm]{rmvt}} in \code{mvtnorm} package. For example, data_generation=list(dist="t-distribution",sigma=list(class_0=diag(5),class_1=diag(5)),df=c(10,10),delta=c(rep(0,5),rep(2,5))).
#' }
#'
#' @param data_input Its default value is NULL and the function will use the "data_generation" parameter to generate the data. If "data_input" is not NULL, the function will ignore the "data_generation" parameter and "n01_all" parameter, and use the "data_input" as the data.
#' Your "data_input" should be a list with "x_data" matrix and "y_data" matrix. For example, \cr\cr
#' \code{
#'
#'yeast_data <- read.table("./yeast.data") \cr}
#'###\link{https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set}\cr\cr
#'\code{
#'x_data = yeast_data[,c(2:5,8:9)]\cr
#'y_label = yeast_data[,10]\cr
#'id0 = which(y_label=="CYT" | y_label=="MIT")\cr
#'y_data = rep(1,length(y_label))\cr
#'y_data[id0] = 0\cr
#' \cr
#'data = list(x_data=x_data, y_data=y_data)\cr\cr
#'
#'AUC = calculate_AUC_base(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), seed=1, method="pca2_mvnorm", model=c("svm","randomforest"), data_input=data)\cr
#' }
#'
#' @param true_data_to_compare 0/1 variable, whether to have the true data to compare with generated data (which could make the output matrix double): if input_data==NULL(run the simulations), we will generate the true data automatically and calculate the AUCs; if you give us the input_data, please make sure that you give us sufficient input data.
#'
#' @return Return the AUCs you want to calculate
#' @export
#'
#' @examples AUC = calculate_AUC_base(n01_all= c(800,800), n01_p=c(15,15), n01_test=c(300,300), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), seed=1, model=c("svm","randomforest"))
calculate_AUC_base <- function(n01_all= c(800,800), n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), seed=1, method="pca2_mvnorm", model=c("svm","randomforest"),func=NULL,data_generation=list(dist="t-distribution",sigma=list(class_0=diag(5),class_1=diag(5)),df=c(10,10),delta=c(rep(0,5),rep(2,5))),data_input=NULL,true_data_to_compare=1)
{
  library(PRROC)
  n0_p <- n01_p[1]
  n1_p <- n01_p[2]

  n0_test <- n01_test[1]
  n1_test <- n01_test[2]
  n_test = n0_test + n1_test

  if(is.null(data_input)){
    data = generate_data(seed=seed, n01_all=n01_all, data_generation=data_generation)
  }else{
    data = data_input
    if(true_data_to_compare==1){
      if(n01_p[1]+n_train_sets[length(n_train_sets)-1]+n01_test[1] > sum(data$y_data==0)){
        stop('error: there are not sufficient class 0 input data to run the simulations! Please adjust the parameters.')
      }
      if(n01_p[2]+n_train_sets[length(n_train_sets)]+n01_test[2] > sum(data$y_data==1)){
        stop('error: there are not sufficient class 1 input data to run the simulations! Please adjust the parameters.')
      }
    }
  }

  pilot_rest_data = split_data(data$x_data, data$y_data, n0_train=n0_p, n1_train=n1_p, seed=seed)

  test_y=c(rep(0,n0_test),rep(1,n1_test))

  Loop=100

  num_of_model = length(model)

  number_of_train_sets = length(n_train_sets)/2

  dim(n_train_sets) = c(2,number_of_train_sets)

  if(true_data_to_compare==0){
    auc = array(0,dim=c(length(n_train_sets)/2,Loop,num_of_model))
  }else{
    auc = array(0,dim=c(length(n_train_sets),Loop,num_of_model))
  }

  adds=0
  for (test_from_true in c(0,1)){

    if(test_from_true==0 && method == "scDesign2"){

      library(scDesign2)
      x_pilot = pilot_rest_data$x_train
      y_pilot = pilot_rest_data$y_train

      id0_p = which(y_pilot==0)
      id1_p = which(y_pilot==1)
      n0_p = length(id0_p)
      n1_p = length(id1_p)
      num_feature = length(x_pilot[id0_p[1],])
      x0_pilot = x_pilot[id0_p,]
      x1_pilot = x_pilot[id1_p,]
      rownames(x0_pilot) = c(rep("0",n0_p))
      rownames(x1_pilot) = c(rep("1",n1_p))

      copula_model_0 <- fit_model_scDesign2(t(x0_pilot), '0', sim_method = 'copula')
      copula_model_1 <- fit_model_scDesign2(t(x1_pilot), '1', sim_method = 'copula')
    }

    for (L in 1:Loop){
      n0_train_max <- max(n_train_sets[1,])
      n1_train_max <- max(n_train_sets[2,])

      if(test_from_true==0){
        if(method == "pca2_mvnorm"){data_list = pilot_tfe_mvnorm_pca2(pilot_rest_data$x_train,pilot_rest_data$y_train,n0_train_max,n1_train_max,n0_test,n1_test)}
        if(method == "gaussian_copula"){data_list = pilot_tfe_gaussian_copula(pilot_rest_data$x_train,pilot_rest_data$y_train,n0_train_max,n1_train_max,n0_test,n1_test)}
        if(method == "smote"){data_list = pilot_tfe_smote(pilot_rest_data$x_train,pilot_rest_data$y_train,n0_train_max,n1_train_max,n0_test,n1_test)}
        if(method == "scDesign2"){data_list = pilot_tfe_scDesign2(pilot_rest_data$x_train,pilot_rest_data$y_train,n0_train_max,n1_train_max,n0_test,n1_test,copula_model_0,copula_model_1)}

      }else if(test_from_true==1){
        train_test_data = split_data(data$x_data, data$y_data, n0_train=n0_train_max, n1_train=n1_train_max, n0_test=n0_test, n1_test=n1_test)

        if(method == "pca2_mvnorm"){data_list = pilot_pca2(train_test_data$x_train,train_test_data$y_train,train_test_data$x_test)}
        if(method == "gaussian_copula"){data_list = pilot_n(train_test_data$x_train,train_test_data$y_train,train_test_data$x_test)}
        if(method == "smote"){data_list = pilot_n(train_test_data$x_train,train_test_data$y_train,train_test_data$x_test)}
        if(method == "scDesign2"){data_list = pilot_pca2(train_test_data$x_train,train_test_data$y_train,train_test_data$x_test)}
      }

      p <- array(0,dim=c(number_of_train_sets,n_test,num_of_model))

      for (i in 1:number_of_train_sets)
      {
        n0_train <- n_train_sets[1,i]
        n1_train <- n_train_sets[2,i]

        data_list_ds = downsample_data(data_list, n0_train = n0_train, n1_train = n1_train, seed = seed)

        result = get_p_result(data_list=data_list_ds, model=model, func=func)

        for(j in 1:num_of_model){
          p[i,,j] = result[j,]
        }

        cat(L,i+adds,"\n")

      }


      for (k in 1:number_of_train_sets)
      {
        index0_test=which(test_y==0)
        index1_test=which(test_y==1)

        for(j in 1:num_of_model){
          score = p[k,,j]
          roc <- roc.curve(scores.class0 =score[index1_test],scores.class1=score[index0_test],curve =FALSE)

          auc[k+adds,L,j]=roc$auc
        }

      }

    }
    if(true_data_to_compare==0){break;}
    adds = adds + number_of_train_sets
  }

  return(auc)
}
